{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction des caractéristiques et création des métadonnées\n",
    "\n",
    "Dans ce notebook (`features-extraction.ipynb`), nous allons effectuer deux étapes principales :\n",
    "\n",
    "1. **Création des métadonnées** : pour chaque image du dataset, nous allons enregistrer son nom de fichier (sans l’extension), ainsi que l’espèce (nom du dossier dans lequel elle se trouve).\n",
    "2. **Extraction des caractéristiques** : nous utiliserons un modèle pré-entraîné (ResNet50) pour extraire des vecteurs de caractéristiques à partir des images.\n",
    "\n",
    "Les images seront traitées dans un ordre aléatoire, mais les informations sur leur espèce d’origine et leur identifiant local seront conservées. Ceci permettra, par la suite, de visualiser facilement les résultats (par exemple, les images appartenant à un même cluster).\n",
    "\n",
    "Le résultat final sera un fichier `.csv` contenant :\n",
    "- Les vecteurs de caractéristiques de chaque image (chaque dimension dans une colonne `feature1`, `feature2`, ... , `feature2048`),\n",
    "- L'espèce correspondante,\n",
    "- L'identifiant de l’image dans son dossier d’origine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation des bibliothèques\n",
    "\n",
    "Importation des modules nécessaires pour le traitement d’images, l’extraction de caractéristiques, et la gestion des données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chargement du modèle\n",
    "\n",
    "Chargement du modèle ResNet50 pré-entraîné (sans la couche de classification) pour extraire des vecteurs de caractéristiques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(weights='imagenet', include_top=False, pooling='avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraction des caractéristiques\n",
    "\n",
    "On parcourt les images du dataset de manière aléatoire ( pour que les clusters ne soient pas ordonnés ), on extrait leurs caractéristiques avec ResNet50, puis on les enregistre avec leur espèce et identifiant dans leur dossier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 811/811 [01:40<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              species id_in_class  feature1  feature2  feature3  feature4  \\\n",
      "0     EMPEROR PENGUIN         016  0.839631  0.367378  0.016061  0.000000   \n",
      "1  AMERICAN GOLDFINCH         085  0.143122  0.187990  0.009073  0.216824   \n",
      "2            FLAMINGO         079  0.166294  0.227275  0.024209  0.410724   \n",
      "3  AMERICAN GOLDFINCH         117  0.787718  0.045966  0.995963  0.127777   \n",
      "4     EMPEROR PENGUIN         127  0.346688  0.002053  0.000000  0.137830   \n",
      "\n",
      "   feature5  feature6  feature7  feature8  ...  feature2039  feature2040  \\\n",
      "0  0.970196  0.030308  0.300561  0.073503  ...     0.033060     0.162204   \n",
      "1  0.017523  1.073512  0.376696  1.023434  ...     0.062616     0.211144   \n",
      "2  0.178875  0.117360  0.001518  0.186852  ...     0.842039     0.235661   \n",
      "3  0.198726  1.341336  0.013681  0.647470  ...     0.785082     0.201939   \n",
      "4  0.975613  0.008014  0.746616  0.254353  ...     0.000000     0.013387   \n",
      "\n",
      "   feature2041  feature2042  feature2043  feature2044  feature2045  \\\n",
      "0     0.238161     0.261353     0.419460     0.000000     1.139953   \n",
      "1     0.678147     0.000000     0.133616     0.127812     1.230054   \n",
      "2     0.352068     0.143582     0.005081     0.791440     1.215837   \n",
      "3     0.155162     0.000000     0.149054     0.043881     0.082104   \n",
      "4     2.487843     0.043601     0.203150     0.000000     1.013455   \n",
      "\n",
      "   feature2046  feature2047  feature2048  \n",
      "0     2.041467     1.581651     0.477702  \n",
      "1     0.850286     0.176419     0.023294  \n",
      "2     0.073673     0.172030     0.047680  \n",
      "3     2.748914     0.562691     0.015624  \n",
      "4     0.090012     0.591919     0.054683  \n",
      "\n",
      "[5 rows x 2050 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "parent_folder = './Bird_Speciees_Dataset'\n",
    "\n",
    "\n",
    "image_info = []\n",
    "\n",
    "# Parcours des images\n",
    "for subdir in os.listdir(parent_folder):\n",
    "    subdir_path = os.path.join(parent_folder, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        for img_name in os.listdir(subdir_path):\n",
    "            img_path = os.path.join(subdir_path, img_name)\n",
    "            if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_info.append({\n",
    "                    \"image_name\": img_name,\n",
    "                    \"species\": subdir        \n",
    "                })\n",
    "\n",
    "# Mélange aléatoire \n",
    "random.shuffle(image_info)\n",
    "\n",
    "\n",
    "# Extraction \n",
    "feature_list = []\n",
    "for info in tqdm(image_info):\n",
    "    img_path = os.path.join(parent_folder, info[\"species\"], info[\"image_name\"])\n",
    "    img_name_no_ext = os.path.splitext(info[\"image_name\"])[0] \n",
    "    \n",
    "    try:\n",
    "        img = image.load_img(img_path, target_size=(224, 224))  \n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)  \n",
    "        \n",
    "        feature_vector = model.predict(x, verbose=0)[0] \n",
    "        \n",
    "        feature_dict = {\"species\": info[\"species\"], \"id_in_class\": img_name_no_ext}\n",
    "        \n",
    "        for i, feature in enumerate(feature_vector):\n",
    "            feature_dict[f\"feature{i+1}\"] = feature\n",
    "        \n",
    "        feature_list.append(feature_dict)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_path}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Convertion to dataframe\n",
    "features_df = pd.DataFrame(feature_list)\n",
    "\n",
    "\n",
    "\n",
    "#verification\n",
    "print(features_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Division des données en ensembles d'entraînement et de test\n",
    "\n",
    "Dans cette étape, les données ont été divisées en deux ensembles distincts : un ensemble d'entraînement (train) et un ensemble de test (test). Cette séparation est cruciale pour évaluer la performance du modèle de manière fiable, en s'assurant que l'ensemble de test n'est pas utilisé pendant l'entraînement.\n",
    "\n",
    "##### Étapes réalisées :\n",
    "1. **Division des données :** L'ensemble de données a été séparé en 70 % pour l'entraînement et 30 % pour le test, à l'aide de la fonction `train_test_split` de Scikit-learn.\n",
    "2. **Sauvegarde des ensembles :** Les ensembles d'entraînement et de test ont été enregistrés dans deux fichiers CSV distincts : `bird_features_train.csv` et `bird_features_test.csv`.\n",
    "\n",
    "**Résultat** :\n",
    "Les ensembles d'entraînement et de test ont été créés et sauvegardés avec succès, prêts à être utilisés pour l'entraînement et l'évaluation de modèles de machine learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les ensembles d'entraînement et de test ont été enregistrés avec succès.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Division en test et train\n",
    "train_df, test_df = train_test_split(features_df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Sauvegarde des deux\n",
    "train_df.to_csv(\"bird_features_train.csv\", index=False)\n",
    "test_df.to_csv(\"bird_features_test.csv\", index=False)\n",
    "\n",
    "print(\"Les ensembles d'entraînement et de test ont été enregistrés avec succès.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
